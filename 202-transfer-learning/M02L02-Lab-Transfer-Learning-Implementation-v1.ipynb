{"cells":[{"cell_type":"markdown","id":"8afe0c15-9bcd-4994-99c6-920fd5868b27","metadata":{},"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","id":"917c0a3e-3a81-40bd-ac3f-a548ec8fbb34","metadata":{},"source":["# Lab: Transfer Learning Implementation \n"]},{"cell_type":"markdown","id":"ecadeb4b-7fd4-4590-b94c-8a322c0707bc","metadata":{},"source":["##### Estimated time needed:  30 minutes\n"]},{"cell_type":"markdown","id":"25da3076-e822-4984-afc3-bb0b5dd23b16","metadata":{},"source":["In this lab, you will learn to implement transfer learning using a pre-trained model in Keras.\n","\n","#### Learning objectives\n","\n","By the end of this lab, you will:\n","\n"," - Import necessary libraries and load the dataset.\n"," - Load a pre-trained model, VGG16, excluding the top layers.\n"," - Add new layers on top of the base model and compile the model.\n"," - Train the model on the new dataset.\n"," - Unfreeze some of the layers of the pre-trained model and fine-tune them.\n","\n"]},{"cell_type":"markdown","id":"a1f3ed27-f588-491b-9997-dbbeb70779ed","metadata":{},"source":["### Step-by-Step Guide: \n","\n","#### Step 1: Setup the Environment \n","\n","Before we start, make sure to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras`. \n"]},{"cell_type":"code","execution_count":1,"id":"769b7642-9ffa-496f-a22b-900f7ebcbad1","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-01-02 18:05:27.278297: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n","2025-01-02 18:05:27.282985: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n","2025-01-02 18:05:27.298918: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-01-02 18:05:27.330393: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-01-02 18:05:27.330453: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-01-02 18:05:27.350421: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-01-02 18:05:29.671502: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["# !pip install tensorflow==2.16.2 matplotlib==3.9.1\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"markdown","id":"135bbd47-c7b2-4e71-968e-200fbe7b8cc9","metadata":{},"source":["##### Explanation:\n","- `tensorflow` is the main library for machine learning in Python.\n","- `Sequential` is used to create a model with a linear stack of layers.\n","- `Dense` and `Flatten` are types of layers that we will use in our model.\n"]},{"cell_type":"markdown","id":"c5fa4e01-165a-4387-aace-da7fd56ce78c","metadata":{},"source":["#### Step 2: Load Pre-trained Model \n"]},{"cell_type":"code","execution_count":2,"id":"3f4e5fb4-7b2b-4487-8cf7-94a2a69aefc4","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"]}],"source":["# Load the VGG16 model pre-trained on ImageNet\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","# Freeze the base model layers\n","for layer in base_model.layers:\n","    layer.trainable = False"]},{"cell_type":"markdown","id":"d0b4ac35-5359-4c74-b7bf-8d4b72007fbb","metadata":{},"source":["#### Step 3: Create and Compile the Model \n"]},{"cell_type":"code","execution_count":3,"id":"9ab87715-f69e-4889-a306-40fe809988b0","metadata":{},"outputs":[],"source":["# Create a new model and add the base model and new layers\n","model = Sequential([\n","    base_model,\n","    Flatten(),\n","    Dense(256, activation='relu'),\n","    Dense(1, activation='sigmoid')  # Change to the number of classes you have\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"markdown","id":"75719b73-022a-479d-8c48-6389a76442a2","metadata":{},"source":["### **Create Placeholder Images**\n"]},{"cell_type":"code","execution_count":4,"id":"9fc34894-ddc4-47f0-a325-34709db0b39e","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Sample images created in 'sample_data/'\n"]}],"source":["import os\n","from PIL import Image\n","import numpy as np\n","\n","# Create directories if they don't exist\n","os.makedirs('sample_data/class_a', exist_ok=True)\n","os.makedirs('sample_data/class_b', exist_ok=True)\n","\n","# Create 10 sample images for each class\n","for i in range(10):\n","    # Create a blank white image for class_a\n","    img = Image.fromarray(np.ones((224, 224, 3), dtype=np.uint8) * 255)\n","    img.save(f'sample_data/class_a/img_{i}.jpg')\n","\n","    # Create a blank black image for class_b\n","    img = Image.fromarray(np.zeros((224, 224, 3), dtype=np.uint8))\n","    img.save(f'sample_data/class_b/img_{i}.jpg')\n","\n","print(\"Sample images created in 'sample_data/'\")\n"]},{"cell_type":"markdown","id":"9c0bb8c1-1073-414e-bae2-8ba3ad029c08","metadata":{},"source":["#### Step 4: Train the Model \n"]},{"cell_type":"code","execution_count":5,"id":"65d62928-699b-465f-a487-e3ab61284fb1","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 20 images belonging to 2 classes.\n","Found 20 images belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/home/user/micromamba/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","2025-01-02 18:06:22.483235: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 256901120 exceeds 10% of free system memory.\n","2025-01-02 18:06:23.073798: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 256901120 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step - accuracy: 0.5000 - loss: 0.6776\n","Epoch 2/10\n"]},{"name":"stderr","output_type":"stream","text":["2025-01-02 18:06:42.991941: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 256901120 exceeds 10% of free system memory.\n","2025-01-02 18:06:43.634300: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 256901120 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.5000 - loss: 5.7977\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["2025-01-02 18:06:59.856386: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 256901120 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 0.5000 - loss: 2.3936\n","Epoch 4/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 1.0000 - loss: 0.5925\n","Epoch 5/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 0.5000 - loss: 0.7013\n","Epoch 6/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 0.5000 - loss: 0.7087\n","Epoch 7/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 0.5000 - loss: 0.7117\n","Epoch 8/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 0.5000 - loss: 0.7100\n","Epoch 9/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 0.5000 - loss: 0.7041\n","Epoch 10/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 0.5000 - loss: 0.6952\n"]}],"source":["# Load and preprocess the dataset\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","train_generator = train_datagen.flow_from_directory(\n","    'sample_data',\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='binary'\n",")\n","\n","# Verify if the generator has loaded images correctly\n","print(f\"Found {train_generator.samples} images belonging to {train_generator.num_classes} classes.\")\n","\n","# Train the model\n","if train_generator.samples > 0:\n","    model.fit(train_generator, epochs=10)"]},{"cell_type":"markdown","id":"ef0924e6-440a-4f04-b917-24f16c7bc643","metadata":{},"source":["#### Step 5: Fine-Tune the Model \n"]},{"cell_type":"code","execution_count":null,"id":"8c54f44f-a7e4-4f31-ae94-c02d8c809fcc","metadata":{},"outputs":[],"source":["# Unfreeze the top layers of the base model \n","\n","for layer in base_model.layers[-4:]:\n","    layer.trainable = True \n","\n","# Compile the model again \n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n","\n","# Train the model again \n","model.fit(train_generator, epochs=10) "]},{"cell_type":"markdown","id":"a9d5e7f8-93b3-466e-aecc-2e51d8a07c35","metadata":{},"source":["### Exercises\n"]},{"cell_type":"markdown","id":"200ce10c-d5da-4972-8c6e-8cfaf7056c0a","metadata":{},"source":["#### Exercise 1: Visualize Training and Validation Loss\n","\n","**Objective:** Plot the training and validation loss to observe the learning process of the model.\n","\n","**Instructions:**\n","1. Modify the training code to include validation data.\n","2. Plot the training and validation loss for each epoch.\n"]},{"cell_type":"code","execution_count":null,"id":"efe25af5-af7e-4398-8474-eb91167597ce","metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","id":"bf1e5eea-ce2d-4090-9b23-186f3d5ed697","metadata":{},"source":["<details>\n","<summary>Click here for solution</summary> </br>\n","\n","```python\n","# Modify data generator to include validation data\n","train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    'sample_data',\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='binary',\n","    subset='training'\n",")\n","\n","validation_generator = train_datagen.flow_from_directory(\n","    'sample_data',\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='binary',\n","    subset='validation'\n",")\n","\n","# Train the model with validation data\n","history = model.fit(train_generator, epochs=10, validation_data=validation_generator)\n","\n","# Plot training and validation loss\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"markdown","id":"490266d9-6dd7-4944-81ce-4615a8cab5f8","metadata":{},"source":["#### Exercise 2: Experiment with Different Optimizers\n","\n","**Objective:** Experiment with different optimizers and observe their impact on model performance.\n","\n","**Instructions:**\n","1. Change the optimizer from `adam` to `sgd` and `rmsprop`.\n","2. Retrain the model with each optimizer and compare the accuracy.\n"]},{"cell_type":"code","execution_count":null,"id":"0ec077e3-cac6-4f43-955b-8c84ef791e58","metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","id":"db02a223-c9bb-4649-b397-50ae12d92d09","metadata":{},"source":["<details>\n","<summary>Click here for solution</summary> </br>\n","\n","```python\n","from tensorflow.keras.models import clone_model\n","import matplotlib.pyplot as plt\n","\n","# Function to reset the model weights\n","def reset_model(model):\n","    # Clone the model to reset weights\n","    model_clone = clone_model(model)\n","    model_clone.set_weights(model.get_weights())\n","    return model_clone\n","\n","# Prepare to reset the model for each optimizer test\n","initial_model = reset_model(model)  # Assume 'model' is the initial compiled model\n","\n","# Experiment with SGD optimizer\n","sgd_model = reset_model(initial_model)  # Reset model\n","sgd_model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n","history_sgd = sgd_model.fit(train_generator, epochs=10, validation_data=validation_generator)\n","\n","# Plot training and validation accuracy for SGD\n","plt.plot(history_sgd.history['accuracy'], label='Training Accuracy SGD')\n","plt.plot(history_sgd.history['val_accuracy'], label='Validation Accuracy SGD')\n","plt.title('Training and Validation Accuracy with SGD')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()\n","\n","# Experiment with RMSprop optimizer\n","rmsprop_model = reset_model(initial_model)  # Reset model\n","rmsprop_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n","history_rmsprop = rmsprop_model.fit(train_generator, epochs=10, validation_data=validation_generator)\n","\n","# Plot training and validation accuracy for RMSprop\n","plt.plot(history_rmsprop.history['accuracy'], label='Training Accuracy RMSprop')\n","plt.plot(history_rmsprop.history['val_accuracy'], label='Validation Accuracy RMSprop')\n","plt.title('Training and Validation Accuracy with RMSprop')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"markdown","id":"731c6f21-35e4-4281-9116-0b302c30b000","metadata":{},"source":["#### Exercise 3: Evaluate the Model on a Test Set\n","\n","**Objective:** Evaluate the fine-tuned model on an unseen test set to assess its generalization performance.\n","\n","**Instructions:**\n","1. Load a separate test set.\n","2. Evaluate the model on this test set and report the accuracy and loss.\n"]},{"cell_type":"code","execution_count":null,"id":"2e9580ec-b3f2-4f51-a668-c227406ac16b","metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","id":"ea02abc8-07d8-4be1-962f-54d29d692a3a","metadata":{},"source":["<details>\n","<summary>Click here for solution</summary> </br>\n","\n","```python\n","# Load and preprocess the test dataset\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = test_datagen.flow_from_directory(\n","    'sample_data',\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='binary'\n",")\n","\n","# Evaluate the fine-tuned model on the test set\n","test_loss, test_accuracy = model.evaluate(test_generator)\n","print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n","print(f'Test Loss: {test_loss:.4f}')\n"]},{"cell_type":"markdown","id":"7fb74232-a593-45cb-9913-7b3553553dfc","metadata":{},"source":["### Summary\n","\n","By completing these exercises, students will:\n","\n","1. Visualize the training and validation loss to gain insights into the training process.\n","2. Experiment with different optimizers to understand their impact on model performance.\n","3. Evaluate the fine-tuned model on an unseen test set to assess its generalization capability.\n"]},{"cell_type":"markdown","id":"0a3acd0a-6ab4-4389-8ed2-b5381b67a970","metadata":{},"source":["#### Conclusion\n","\n","Congratulations! In this lab, you have successfully implemented transfer learning using a pre-trained model in Keras. This lab exercise demonstrated how to train and fine-tune the model by unfreezing some of the layers.\n"]},{"cell_type":"markdown","id":"ad8a425e-4959-4b3b-ae47-9b2445326c25","metadata":{},"source":["Copyright © IBM Corporation. All rights reserved.\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.21"},"prev_pub_hash":"46890cfd422ab815a33a7c99b85ad21a549fbfa26e2bfd3ec07a5686815da9bc"},"nbformat":4,"nbformat_minor":4}
