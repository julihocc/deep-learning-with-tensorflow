{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julihocc/edx-ibm-DL0120EN/blob/main/301-advanced-transformers/REVIEW-Lab-Building%20Advanced%20Transformers-v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdb08ae3-6e40-4e75-900d-da6aeb43993a"
      },
      "source": [
        "<p style=\"text-align:center\">\n",
        "    <a href=\"https://skills.network\" target=\"_blank\">\n",
        "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
        "    </a>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37fcf9da-864f-4d9e-b0da-5f995396dd17"
      },
      "source": [
        "# **Lab: Building Advanced Transformers**\n",
        "\n",
        "**Estimated time needed:  30 minutes**  \n",
        "\n",
        "In this lab, you will implement and experiment with advanced Transformer models using Keras.\n",
        "\n",
        "**Learning objectives:**\n",
        "\n",
        "By the end of this lab, you will:\n",
        "\n",
        "- Implement advanced Transformer models using Keras.\n",
        "\n",
        "- Apply Transformers to real-world sequential data tasks.\n",
        "\n",
        "- Build, train, and evaluate Transformer models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1f99b57-2c59-4862-8fac-9ff12df49057"
      },
      "source": [
        "## Step-by-Step Instructions:\n",
        "\n",
        "### Step 1: Import necessary libraries\n",
        "\n",
        "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras.`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f75f47fd-ad84-4ee2-bc2c-6311baafb7fb"
      },
      "outputs": [],
      "source": [
        "# %pip install tensorflow pyarrow\n",
        "# %pip install pandas\n",
        "# %pip install scikit-learn\n",
        "# %pip install matplotlib\n",
        "# %pip install requests"
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7b493f8-9f56-4ea0-97cf-bb6c4f3ebfab"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import requests\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84a6fc6c-1977-442d-a622-0794062257e1"
      },
      "source": [
        "####  Setup the Environment to generate synthetic stock price data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7a1644f-1983-4208-823e-1923cc2be243",
        "outputId": "d9307a2b-8dbf-4921-cd47-b8fa944f9576",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic stock_prices.csv created and loaded.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Create a synthetic stock price dataset\n",
        "np.random.seed(42)\n",
        "data_length = 2000  # Adjust data length as needed\n",
        "trend = np.linspace(100, 200, data_length)\n",
        "noise = np.random.normal(0, 2, data_length)\n",
        "synthetic_data = trend + noise\n",
        "\n",
        "# Create a DataFrame and save as 'stock_prices.csv'\n",
        "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
        "data.to_csv('stock_prices.csv', index=False)\n",
        "print(\"Synthetic stock_prices.csv created and loaded.\")\n"
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b9f0a73-eb0e-4c0b-adb1-2f068a5f33d7",
        "outputId": "fd6ca75d-c8a5-43e6-df6a-d0677f20f7c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (1899, 100, 1)\n",
            "Shape of Y: (1899,)\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('stock_prices.csv')\n",
        "data = data[['Close']].values\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data = scaler.fit_transform(data)\n",
        "\n",
        "# Prepare the data for training\n",
        "def create_dataset(data, time_step=1):\n",
        "    X, Y = [], []\n",
        "\n",
        "    for i in range(len(data)-time_step-1):\n",
        "        a = data[i:(i+time_step), 0]\n",
        "        X.append(a)\n",
        "        Y.append(data[i + time_step, 0])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "time_step = 100\n",
        "X, Y = create_dataset(data, time_step)\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of Y:\", Y.shape)"
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b218abb-d401-4727-a317-2e381c2d1103"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "`tensorflow` is the main library for machine learning in Python.  \n",
        "\n",
        "`stock_prices.csv` is the data set that is loaded.\n",
        "\n",
        "`MinMaxScaler` method is used to normalize the data.  \n",
        "\n",
        "`create_dataset`method is used to prepare the data for training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "834533dc-d545-4225-abe5-bf6702a63b29"
      },
      "source": [
        "### Step 2: Implement Multi-Head Self-Attention\n",
        "\n",
        "Define the Multi-Head Self-Attention mechanism.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c17e005d-bb96-4e35-84f6-1b64ff95198f"
      },
      "outputs": [],
      "source": [
        "class MultiHeadSelfAttention(Layer):\n",
        "\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = Dense(embed_dim)\n",
        "        self.key_dense = Dense(embed_dim)\n",
        "        self.value_dense = Dense(embed_dim)\n",
        "        self.combine_heads = Dense(embed_dim)\n",
        "\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)\n",
        "        key = self.key_dense(inputs)\n",
        "        value = self.value_dense(inputs)\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "        attention, _ = self.attention(query, key, value)\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
        "        output = self.combine_heads(concat_attention)\n",
        "        return output\n",
        "\n",
        ""
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9559b2f1-6474-4761-b3e1-e8d463be0b80"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously.\n",
        "\n",
        "- The attention parameter computes the attention scores and weighted sum of the values.\n",
        "\n",
        "- The split_heads parameter splits the input into multiple heads for parallel attention computation.\n",
        "\n",
        "- The call method applies the self-attention mechanism and combines the heads.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19eacfd8-cf47-49e2-b3d6-37f4a9f7fc91"
      },
      "source": [
        "### Step 3: Implement Transformer block\n",
        "\n",
        "Define the Transformer block.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d98b16c-1273-47db-a7c1-1b86c156f923"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(Layer):\n",
        "\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59ac1a9c-a6fd-426a-8150-7d73bbda0260"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.  \n",
        "\n",
        "- Dropout is used to prevent overfitting.\n",
        "\n",
        "- The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44236ed7-6e90-4272-8ddb-0b23f162e801"
      },
      "source": [
        "### Step 4: Implement Encoder Layer\n",
        "\n",
        "Define the Encoder layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ae62188-09fc-4efa-be57-4ccdc7388d06"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(Layer):\n",
        "\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n"
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9c4a011-d544-467e-8dd4-5b785a226924"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture.\n",
        "\n",
        "- It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network.\n",
        "\n",
        "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer.\n",
        "\n",
        "- The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4d804e1-689b-4876-be82-6a65a1381154"
      },
      "source": [
        "### Step 5: Implement Transformer encoder\n",
        "\n",
        "Define the Transformer Encoder.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4cc36bd-6bd8-4334-8571-d3ec5a17c69e",
        "outputId": "203cdd2c-4525-4df3-cc93-0f88d60176c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'transformer_encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 100, 128)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout\n",
        "\n",
        "class MultiHeadSelfAttention(Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = Dense(embed_dim)\n",
        "        self.key_dense = Dense(embed_dim)\n",
        "        self.value_dense = Dense(embed_dim)\n",
        "        self.combine_heads = Dense(embed_dim)\n",
        "\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)\n",
        "        key = self.key_dense(inputs)\n",
        "        value = self.value_dense(inputs)\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "        attention, _ = self.attention(query, key, value)\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
        "        output = self.combine_heads(concat_attention)\n",
        "        return output\n",
        "\n",
        "class TransformerBlock(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class TransformerEncoder(Layer):\n",
        "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.embed_dim = embed_dim\n",
        "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)]\n",
        "        self.dropout = Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = inputs\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training=training)\n",
        "        return x\n",
        "\n",
        "# Example usage\n",
        "embed_dim = 128\n",
        "num_heads = 8\n",
        "ff_dim = 512\n",
        "num_layers = 4\n",
        "\n",
        "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim)\n",
        "inputs = tf.random.uniform((1, 100, embed_dim))\n",
        "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training'\n",
        "print(outputs.shape)  # Should print (1, 100, 128)"
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58914cf7-70fa-4e3a-9a13-2c7ea907f91e"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ade3a268-1398-489b-965b-63d7cb4f70b9"
      },
      "source": [
        "### Step 6: Build and Compile the Transformer model\n",
        "\n",
        "Integrate the Transformer Encoder into a complete model for sequential data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "973dc690-4c2f-4edf-aa69-63be850f3ece",
        "outputId": "6b285c13-5030-45bb-8caf-0fe822bd18bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'transformer_encoder_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m793,088\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │          \u001b[38;5;34m12,801\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Define the necessary parameters\n",
        "\n",
        "embed_dim = 128\n",
        "num_heads = 8\n",
        "ff_dim = 512\n",
        "num_layers = 4\n",
        "\n",
        "# Define the Transformer Encoder\n",
        "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim)\n",
        "\n",
        "# Build the model\n",
        "input_shape = (X.shape[1], X.shape[2])\n",
        "inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "# Project the inputs to the embed_dim\n",
        "x = tf.keras.layers.Dense(embed_dim)(inputs)\n",
        "encoder_outputs = transformer_encoder(x)\n",
        "flatten = tf.keras.layers.Flatten()(encoder_outputs)\n",
        "outputs = tf.keras.layers.Dense(1)(flatten)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n"
      ],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51fb9cf5-9372-4794-add8-5f2392838a23"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.  \n",
        "\n",
        "- The model is then compiled with the Adam optimizer and mean squared error loss.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5978fb3-3a42-44f9-b146-68cad41ba794"
      },
      "source": [
        "### Step 7: Train the Transformer model\n",
        "\n",
        "Train the model on the prepared dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a65d7244-5b68-4ba7-9f94-27cb0022e768",
        "outputId": "880cf1c6-601e-48c6-b80b-736a6a865776",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 242ms/step - loss: 14.7023\n",
            "Epoch 2/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1963\n",
            "Epoch 3/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1378\n",
            "Epoch 4/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1631\n",
            "Epoch 5/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1380\n",
            "Epoch 6/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1609\n",
            "Epoch 7/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1050\n",
            "Epoch 8/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1289\n",
            "Epoch 9/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1137\n",
            "Epoch 10/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1013\n",
            "Epoch 11/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0999\n",
            "Epoch 12/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1329\n",
            "Epoch 13/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1432\n",
            "Epoch 14/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0797\n",
            "Epoch 15/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0792\n",
            "Epoch 16/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0998\n",
            "Epoch 17/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0680\n",
            "Epoch 18/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1071\n",
            "Epoch 19/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0615\n",
            "Epoch 20/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0499\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d16e1e00fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(X, Y, epochs=20, batch_size=32)\n"
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aa04758-fc9b-4fb2-b00e-535326f274a6"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14dc0b3a-758e-407e-b392-cd3b9a1c2fa1",
        "outputId": "ed9625bf-d6f3-42c3-fe69-d1e8a056072f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Make predictions\n",
        "predictions = model.predict(X)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "\n",
        "# Plot the predictions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(data, label='True Data')\n",
        "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        ""
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98c73638-a697-414f-91b4-3cf1455015db"
      },
      "source": [
        "### Step 8: Evaluate and Make Predictions\n",
        "\n",
        "Evaluate the model's performance and make predictions on the dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7654ac42-8a22-4304-b257-2d344dcd360f"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The model's predictions are transformed back to the original scale using the inverse transform of the scaler.\n",
        "\n",
        "- The true data and predictions are plotted to visualize the model's performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c9e038e-2bd0-48df-a073-317143f34a65"
      },
      "source": [
        "## Practice Exercises:\n",
        "\n",
        " ### Exercise 1: Add dropout to the Transformer model\n",
        "\n",
        " **Objective: Understand how to add dropout layers to the Transformer model to prevent overfitting.**\n",
        "\n",
        " Instructions:\n",
        "\n",
        "- Add a dropout layer after the Flatten layer in the model.\n",
        "\n",
        "- Set the dropout rate to 0.5.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "658814d0-81f8-4e42-9196-f58a8ba73174",
        "outputId": "cf0bb29b-2a86-4299-db48-c6662c81cd39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 223ms/step - loss: 3.4969\n",
            "Epoch 2/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 1.2357\n",
            "Epoch 3/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.6345\n",
            "Epoch 4/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.3085\n",
            "Epoch 5/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1231\n",
            "Epoch 6/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0521\n",
            "Epoch 7/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0373\n",
            "Epoch 8/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0215\n",
            "Epoch 9/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0187\n",
            "Epoch 10/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0183\n",
            "Epoch 11/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0150\n",
            "Epoch 12/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0168\n",
            "Epoch 13/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0124\n",
            "Epoch 14/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0167\n",
            "Epoch 15/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0123\n",
            "Epoch 16/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0193\n",
            "Epoch 17/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0122\n",
            "Epoch 18/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0099\n",
            "Epoch 19/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0102\n",
            "Epoch 20/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0134\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 0.0021\n",
            "Test loss: 0.004281660076230764\n"
          ]
        }
      ],
      "source": [
        "## Write your code here.\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "\n",
        "\n",
        "# Add a dropout layer after the Flatten layer\n",
        "\n",
        "flatten = tf.keras.layers.Flatten()(encoder_outputs)\n",
        "\n",
        "dropout = Dropout(0.5)(flatten)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(1)(dropout)\n",
        "\n",
        "\n",
        "\n",
        "# Build the model\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "\n",
        "\n",
        "# Train the model\n",
        "\n",
        "model.fit(X, Y, epochs=20, batch_size=32)\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "\n",
        "loss = model.evaluate(X, Y)\n",
        "\n",
        "print(f'Test loss: {loss}')"
      ],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b631728-90c3-4045-9a46-4981381b9f26"
      },
      "source": [
        "<details><summary>Click here to view the solution.</summary>\n",
        "\n",
        "```\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "  \n",
        "\n",
        "# Add a dropout layer after the Flatten layer\n",
        "\n",
        "flatten = tf.keras.layers.Flatten()(encoder_outputs)\n",
        "\n",
        "dropout = Dropout(0.5)(flatten)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(1)(dropout)\n",
        "\n",
        "  \n",
        "\n",
        "# Build the model\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "  \n",
        "\n",
        "# Compile the model\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "  \n",
        "\n",
        "# Train the model\n",
        "\n",
        "model.fit(X, Y, epochs=20, batch_size=32)\n",
        "\n",
        "  \n",
        "\n",
        "# Evaluate the model\n",
        "\n",
        "loss = model.evaluate(X, Y)\n",
        "\n",
        "print(f'Test loss: {loss}')\n",
        "\n",
        "```\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ac4285e-8886-47e6-8946-e10493394914"
      },
      "source": [
        "### Exercise 2: Experiment with different batch sizes\n",
        "\n",
        "**Objective: Observe the impact of different batch sizes on model performance.**\n",
        "\n",
        " Instructions:\n",
        "\n",
        "- Train the model with a batch size of 16.\n",
        "\n",
        "- Train the model with a batch size of 64.\n",
        "\n",
        "- Compare the training time and performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "960017cb-8c0e-4d60-9447-81f4be936add",
        "outputId": "05e675fd-4843-4289-81b1-a22542e068ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - loss: 0.0259\n",
            "Epoch 2/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0360\n",
            "Epoch 3/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0298\n",
            "Epoch 4/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0182\n",
            "Epoch 5/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0536\n",
            "Epoch 6/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0240\n",
            "Epoch 7/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0209\n",
            "Epoch 8/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0141\n",
            "Epoch 9/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0124\n",
            "Epoch 10/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0099\n",
            "Epoch 11/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0162\n",
            "Epoch 12/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0161\n",
            "Epoch 13/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0173\n",
            "Epoch 14/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0130\n",
            "Epoch 15/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0082\n",
            "Epoch 16/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0083\n",
            "Epoch 17/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0120\n",
            "Epoch 18/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.0083\n",
            "Epoch 19/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0068\n",
            "Epoch 20/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0108\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038\n",
            "Test loss with batch size 16: 0.001833121757954359\n",
            "Epoch 1/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 480ms/step - loss: 0.0080\n",
            "Epoch 2/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - loss: 0.0049\n",
            "Epoch 3/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0033\n",
            "Epoch 4/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0031\n",
            "Epoch 5/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0028\n",
            "Epoch 6/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0032\n",
            "Epoch 7/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0030\n",
            "Epoch 8/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0025\n",
            "Epoch 9/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0027\n",
            "Epoch 10/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0028\n",
            "Epoch 11/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0023\n",
            "Epoch 12/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0023\n",
            "Epoch 13/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0027\n",
            "Epoch 14/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0022\n",
            "Epoch 15/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0024\n",
            "Epoch 16/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0025\n",
            "Epoch 17/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0021\n",
            "Epoch 18/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0023\n",
            "Epoch 19/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0024\n",
            "Epoch 20/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0025\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2964e-04\n",
            "Test loss with batch size 64: 0.0005285931983962655\n"
          ]
        }
      ],
      "source": [
        "# Train the model with batch size 16\n",
        "model.fit(X, Y, epochs=20, batch_size=16)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f'Test loss with batch size 16: {loss}')\n",
        "\n",
        "# Train the model with batch size 64\n",
        "model.fit(X, Y, epochs=20, batch_size=64)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f'Test loss with batch size 64: {loss}')\n"
      ],
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32f752d7-fece-4267-9164-9a64bcae3911"
      },
      "source": [
        "<details><summary>Click here to view the solution.</summary>\n",
        "\n",
        "```\n",
        "# Train the model with batch size 16\n",
        "model.fit(X, Y, epochs=20, batch_size=16)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f'Test loss with batch size 16: {loss}')\n",
        "\n",
        "# Train the model with batch size 64\n",
        "model.fit(X, Y, epochs=20, batch_size=64)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f'Test loss with batch size 64: {loss}')\n",
        "\n",
        "```\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "359aec66-7a1c-4f1b-9be3-6a7f90905c3d"
      },
      "source": [
        "### Exercise 3: Use a different activation function\n",
        "\n",
        " **Objective: Understand how different activation functions impact the model performance.**\n",
        "\n",
        " Instructions:\n",
        "\n",
        "- Change the activation function of the Dense layer to `tanh`.\n",
        "\n",
        "- Train and evaluate the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "194078fc-6b2a-4543-8200-b3d6c9e71e57",
        "outputId": "52b44e2e-96f0-48bf-f7fe-c8e30d0306f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 221ms/step - loss: 0.0827\n",
            "Epoch 2/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0106\n",
            "Epoch 3/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0038\n",
            "Epoch 4/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0028\n",
            "Epoch 5/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0020\n",
            "Epoch 6/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0024\n",
            "Epoch 7/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0026\n",
            "Epoch 8/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0019\n",
            "Epoch 9/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0019\n",
            "Epoch 10/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0022\n",
            "Epoch 11/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0029\n",
            "Epoch 12/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0040\n",
            "Epoch 13/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0029\n",
            "Epoch 14/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0020\n",
            "Epoch 15/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0021\n",
            "Epoch 16/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0022\n",
            "Epoch 17/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0021\n",
            "Epoch 18/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0021\n",
            "Epoch 19/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0022\n",
            "Epoch 20/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0026\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 6.3410e-04\n",
            "Test loss with tanh activation: 0.0007199210813269019\n"
          ]
        }
      ],
      "source": [
        "# Change the activation function of the Dense layer to tanh\n",
        "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, Y, epochs=20, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f'Test loss with tanh activation: {loss}')\n"
      ],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ade7ca29-e106-4a76-97b6-5fd814a01a0e"
      },
      "source": [
        "<details><summary>Click here to view the solution.</summary>\n",
        "\n",
        "```\n",
        "# Change the activation function of the Dense layer to tanh\n",
        "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, Y, epochs=20, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f'Test loss with tanh activation: {loss}')\n",
        "\n",
        "```\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27b057d6-dab5-465e-bfc2-a2e1238297ad"
      },
      "source": [
        "## Conclusion\n",
        "Congratulations on completing this lab! In this lab, you have built an advanced Transformer model using Keras and applied it to a time series forecasting task. You have learned how to define and implement multi-head self-attention, Transformer blocks, encoder layers, and integrate them into a complete Transformer model. By experimenting with different configurations and training the model, you can further improve its performance and apply it to various sequential data tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d130ec79-66d4-4f13-9e97-f5d0508ec412"
      },
      "source": [
        "Copyright © IBM Corporation. All rights reserved.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "prev_pub_hash": "28ac4fd81c1d713f83dcd1cdf1d3383ad25ea92873288fe9e978e9a17b314709",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}